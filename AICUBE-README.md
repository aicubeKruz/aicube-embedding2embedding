# AICUBE Embedding2Embedding API

## VisÃ£o Geral

A **AICUBE Embedding2Embedding API** Ã© um serviÃ§o desenvolvido pela **AICUBE TECHNOLOGY** que permite traduzir embeddings entre diferentes espaÃ§os vetoriais de modelos de linguagem natural. Utilizando tecnologias avanÃ§adas como **Qube LCM Model**, **Qube Neural Memory**, **Qube Agentic Workflows** e **Qube Computer Vision**, a API preserva o significado semÃ¢ntico durante a conversÃ£o.

## Tecnologias AICUBE Utilizadas

- **Qube LCM Model**: Modelo de linguagem contextual avanÃ§ado
- **Qube Neural Memory**: Sistema de memÃ³ria neural para preservaÃ§Ã£o semÃ¢ntica
- **Qube Agentic Workflows**: Fluxos de trabalho inteligentes e autÃ´nomos
- **Qube Computer Vision**: Processamento visual avanÃ§ado para anÃ¡lise multimodal

## CaracterÃ­sticas Principais

### ğŸš€ Performance Otimizada
- Arquitetura baseada em MLP com conexÃµes residuais
- AtivaÃ§Ã£o SiLU para melhor convergÃªncia
- NormalizaÃ§Ã£o de camadas para estabilidade
- Suporte a processamento em batch

### ğŸ”„ Interoperabilidade
- TraduÃ§Ã£o entre modelos populares (BERT, T5, RoBERTa, GPT-2, OpenAI Ada-002)
- PreservaÃ§Ã£o de similaridade semÃ¢ntica (>90% de similaridade cosseno)
- Suporte a diferentes dimensionalidades de embedding

### ğŸ“Š Monitoramento AvanÃ§ado
- Logging estruturado com mÃ©tricas detalhadas
- Health checks automÃ¡ticos
- EstatÃ­sticas de uso em tempo real
- Rastreamento de performance

### ğŸ”§ Flexibilidade
- ConfiguraÃ§Ã£o via variÃ¡veis de ambiente
- Carregamento dinÃ¢mico de modelos
- Cache inteligente para otimizaÃ§Ã£o
- API RESTful com documentaÃ§Ã£o OpenAPI

## InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos
- Python 3.11+
- Docker (opcional)
- CUDA (opcional, para aceleraÃ§Ã£o GPU)

### InstalaÃ§Ã£o com Docker (Recomendado)

```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd aicube-embedding2embedding

# Build da imagem
docker build -f aicube-Dockerfile -t aicube-embedding2embedding .

# Executar com Docker Compose
docker-compose -f aicube-docker-compose.yml up -d
```

### InstalaÃ§Ã£o Manual

```bash
# Criar ambiente virtual
python -m venv aicube-env
source aicube-env/bin/activate  # Linux/Mac
# ou
aicube-env\Scripts\activate  # Windows

# Instalar dependÃªncias
pip install -r aicube-requirements.txt

# Configurar variÃ¡veis de ambiente
cp aicube.env.example aicube.env
# Editar aicube.env conforme necessÃ¡rio

# Executar aplicaÃ§Ã£o
python aicube-app/aicube-main.py
```

## Uso da API

### Endpoints Principais

#### 1. Traduzir Embedding
```http
POST /api/v1/translate
Content-Type: application/json

{
  "origem": "bert_base_uncased",
  "destino": "t5_base", 
  "embedding": [0.12, 0.45, -0.67, 0.89, -0.23],
  "include_metadata": true
}
```

**Resposta:**
```json
{
  "origem": "bert_base_uncased",
  "destino": "t5_base",
  "embedding_traduzido": [0.08, 0.33, -0.10, 0.71, -0.15],
  "aicube_technology": "AICUBE TECHNOLOGY",
  "metadata": {
    "aicube_model_id": "aicube-bert-to-t5",
    "duration_ms": 15.2,
    "cosine_similarity": 0.94,
    "powered_by": ["Qube LCM Model", "Qube Neural Memory"]
  }
}
```

#### 2. TraduÃ§Ã£o em Lote
```http
POST /api/v1/translate/batch
Content-Type: application/json

{
  "origem": "bert_base_uncased",
  "destino": "t5_base",
  "embeddings": [
    [0.12, 0.45, -0.67],
    [0.89, -0.23, 0.56]
  ],
  "include_metadata": true
}
```

#### 3. Listar Modelos DisponÃ­veis
```http
GET /api/v1/models
```

#### 4. Health Check
```http
GET /api/v1/health
```

#### 5. EstatÃ­sticas de Uso
```http
GET /api/v1/statistics
```

### Modelos Suportados

| Modelo de Origem | Modelo de Destino | Tradutor AICUBE | Tecnologia |
|-----------------|------------------|-----------------|------------|
| bert_base_uncased | t5_base | aicube-bert-to-t5 | Qube LCM Model |
| sentence_transformers_mpnet | openai_ada002 | aicube-mpnet-to-ada002 | Qube Neural Memory |
| roberta_base | gpt2_base | aicube-roberta-to-gpt2 | Qube Agentic Workflows |

## Arquitetura

### Camadas da AplicaÃ§Ã£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        AICUBE API Layer             â”‚
â”‚  (FastAPI + Pydantic Validation)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      AICUBE Business Logic          â”‚
â”‚   (Model Manager + Validators)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     AICUBE ML Translation Layer     â”‚
â”‚  (Neural Networks + PyTorch)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes Principais

- **aicube-main.py**: AplicaÃ§Ã£o FastAPI principal
- **aicube-model-manager.py**: Gerenciador de modelos de traduÃ§Ã£o
- **aicube-embedding-translator.py**: Modelos neurais de traduÃ§Ã£o
- **aicube-endpoints.py**: DefiniÃ§Ã£o dos endpoints REST
- **aicube-schemas.py**: ValidaÃ§Ã£o de dados com Pydantic
- **aicube-logging.py**: Sistema de logging estruturado

## ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

| VariÃ¡vel | DescriÃ§Ã£o | PadrÃ£o |
|----------|-----------|--------|
| `AICUBE_API_NAME` | Nome da API | aicube-embedding2embedding |
| `AICUBE_MODELS_PATH` | Caminho dos modelos | ./aicube-models |
| `AICUBE_MAX_EMBEDDING_DIMENSION` | DimensÃ£o mÃ¡xima | 4096 |
| `AICUBE_MAX_BATCH_SIZE` | Tamanho mÃ¡ximo do batch | 32 |
| `AICUBE_DEVICE` | Dispositivo (cpu/cuda) | cpu |

### Logging

O sistema utiliza logging estruturado com contexto AICUBE:

```json
{
  "timestamp": "2023-06-19T12:00:00Z",
  "level": "info",
  "message": "AICUBE Embedding Translation",
  "aicube_service": "aicube-embedding2embedding",
  "aicube_technology": "AICUBE TECHNOLOGY",
  "source_model": "bert_base_uncased",
  "target_model": "t5_base",
  "duration_ms": 15.2,
  "cosine_similarity": 0.94
}
```

## Desenvolvimento

### Estrutura do Projeto

```
aicube-embedding2embedding/
â”œâ”€â”€ aicube-app/                    # CÃ³digo principal
â”‚   â”œâ”€â”€ aicube-api/               # Endpoints REST
â”‚   â”œâ”€â”€ aicube-core/              # LÃ³gica central
â”‚   â”œâ”€â”€ aicube-models/            # Modelos ML
â”‚   â””â”€â”€ aicube-utils/             # UtilitÃ¡rios
â”œâ”€â”€ aicube-tests/                 # Testes
â”œâ”€â”€ aicube-models/                # Modelos prÃ©-treinados
â”œâ”€â”€ aicube-docs/                  # DocumentaÃ§Ã£o
â”œâ”€â”€ aicube-configs/               # ConfiguraÃ§Ãµes
â””â”€â”€ aicube-scripts/               # Scripts auxiliares
```

### Executar Testes

```bash
# Testes unitÃ¡rios
pytest aicube-tests/aicube-unit/ -v

# Testes de integraÃ§Ã£o
pytest aicube-tests/aicube-integration/ -v

# Coverage
pytest --cov=aicube-app aicube-tests/
```

### Adicionar Novo Modelo

1. Treinar modelo de traduÃ§Ã£o
2. Salvar no formato AICUBE (.pt)
3. Adicionar entrada em `aicube-model-registry.json`
4. Atualizar documentaÃ§Ã£o

## MÃ©tricas e Monitoramento

### MÃ©tricas DisponÃ­veis

- **LatÃªncia**: Tempo de resposta por requisiÃ§Ã£o
- **Throughput**: RequisiÃ§Ãµes por segundo
- **Similaridade**: Qualidade da traduÃ§Ã£o (similaridade cosseno)
- **Uso de Modelos**: EstatÃ­sticas por modelo
- **Erros**: Taxa de erro e tipos

### Dashboards

A API expÃµe mÃ©tricas no formato Prometheus em `/metrics` (porta 8001):

```
# HELP aicube_translation_duration_seconds Time spent translating embeddings
# TYPE aicube_translation_duration_seconds histogram
aicube_translation_duration_seconds_bucket{model="aicube-bert-to-t5",le="0.01"} 150
```

## Performance

### Benchmarks

| Modelo | DimensÃ£o | LatÃªncia (ms) | Similaridade | Throughput (req/s) |
|--------|----------|---------------|--------------|-------------------|
| BERTâ†’T5 | 768â†’768 | 15.2 | 0.94 | 65 |
| MPNetâ†’Ada002 | 768â†’1536 | 23.1 | 0.93 | 43 |
| RoBERTaâ†’GPT2 | 768â†’768 | 18.7 | 0.92 | 53 |

### OtimizaÃ§Ãµes

- **Batch Processing**: Processe mÃºltiplos embeddings juntos
- **Model Caching**: Mantenha modelos carregados em memÃ³ria
- **GPU Acceleration**: Use CUDA quando disponÃ­vel
- **QuantizaÃ§Ã£o**: Modelos quantizados para menor latÃªncia

## Casos de Uso

### 1. Setor Financeiro
- AnÃ¡lise de sentimento em notÃ­cias financeiras
- DetecÃ§Ã£o de fraudes em transaÃ§Ãµes
- Chatbots especializados em finanÃ§as

### 2. Setor de Seguros
- Processamento de sinistros
- AnÃ¡lise multimodal (texto + imagem)
- ClassificaÃ§Ã£o automÃ¡tica de reclamaÃ§Ãµes

### 3. Varejo
- RecomendaÃ§Ãµes de produtos
- Busca semÃ¢ntica multilÃ­ngue
- AnÃ¡lise de reviews de clientes

### 4. JurÃ­dico
- Pesquisa de jurisprudÃªncia
- AnÃ¡lise de contratos
- E-discovery automatizado

## Suporte e ContribuiÃ§Ã£o

### Reportar Issues
Para reportar bugs ou solicitar funcionalidades, use o sistema de issues com as tags:
- `aicube-bug`: Para bugs
- `aicube-enhancement`: Para novas funcionalidades
- `aicube-question`: Para dÃºvidas

### Contribuir
1. Fork o repositÃ³rio
2. Crie branch com prefixo `aicube-feature/`
3. Implemente seguindo os padrÃµes AICUBE
4. Adicione testes com prefixo `aicube_test_`
5. Submeta pull request

### LicenÃ§a
Este projeto Ã© propriedade da **AICUBE TECHNOLOGY** e utiliza tecnologias proprietÃ¡rias.

---

**Desenvolvido por AICUBE TECHNOLOGY**  
Powered by Qube LCM Model, Qube Neural Memory, Qube Agentic Workflows e Qube Computer Vision